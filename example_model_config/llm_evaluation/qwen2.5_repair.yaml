llm_config:
  model_name: "Qwen/Qwen2.5-Coder-32B"
  quantization: "8bit"
  generate_config:
    max_new_tokens: 1024 # https://github.com/codetlingua/codetlingua/blob/fceef6996112cf046e5cedaacd8a691e983bc2ee/translate/model.py#L437C94-L437C98
    return_dict_in_generate: True
    output_logits: True

task_config:
  split: "iidai/avatar"
  repair_data_path: "LLM_repair/Defects4j/single_function_repair.json"
  repair_loc_folder: "LLM_repair/Defects4j/location/"

system_setting: # change to "" if you want to use default huggingface path.
  HF_HOME: "/data/data_disk/huggingface"
  cache_dir: '/data/data_disk/huggingface/hub/'
  JAVA_PATH: "/usr/lib/jvm/java-8-openjdk-amd64"
  DEFECTS4J_PATH: "/home/defects4j/framework/bin"